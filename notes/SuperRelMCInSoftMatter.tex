\documentclass[a4paper]{article}
\usepackage[margin=2.5cm]{geometry}
\usepackage{amsmath}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{float}
\usepackage{subfigure}
\usepackage[plain,noend]{algorithm2e}
\usepackage{verbatim}
\input{latex_commands.tex}

\begin{document}
\title{Super-relativistic Monte Carlo with a temperature-generalised kinetic energy: robust and efficient all-atom simulation from a single set of tuning parameters (we hope...)}
\author{Michael Faulkner}
\date{\today}

\maketitle


\section{All-atom models in soft-matter physics}

The potential of two charged point particles at positions $\rvec_1, \rvec_2$ on a three-dimensional compact subspace $\Omega$ of Euclidean space is (approximately) given by
\begin{align}
U_c(\rvec_1, \rvec_2) = \pm \frac{1}{\normbrackets{\rvec_1 - \rvec_2}} + U_{\rm{self}} 
\end{align}
for like / opposite charge values. For the opposite-charge case, we note that an additional Lennard-Jones term induces a short-distance cutoff $a > 0$, which prevents divergences. This statement is approximate because the correct potential accounts for the interactions between these particles and all of their images in each infinite periodic repetition of $\Omega$ (i.e., the periodic boundaries / torus), but this isn't important for the following argument. 

The total potential of two charge-neutral dipoles, each of which is composed of a positive and a negative point charge coupled via a harmonic-spring potential, may then be given by:
\begin{align}
U_{\rm dipoles} (\rvec_1, \rvec_2, \rvec_3, \rvec_4) =& \sum_{i = 1}^2 \sum_{j = 3}^4 \bracketsd{k_c \frac{c_i c_j}{\normbrackets{\rvec_i - \rvec_j}} + k_{lj} \bracketsc{\bracketsb{\frac{\sigma}{\normbrackets{\rvec_i - \rvec_j}}}^{12} - \bracketsb{\frac{\sigma}{\normbrackets{\rvec_i - \rvec_j}}}^6}} \nonumber\\
&+ \frac{k_h}{2} \bracketsc{\bracketsb{\normbrackets{\rvec_1 - \rvec_2} - r_0}^2 + \bracketsb{\normbrackets{\rvec_3 - \rvec_4} - r_0}^2} ,
\end{align}
where $k_c, k_{lj}, k_h > 0$ are the Coulomb, Lennard-Jones and harmonic constants, the final term is the intramolecular harmonic-spring potential, and the other terms are the intermolecular potentials (the second of which is the Lennard-Jones potential). One of the major goals of molecular-dynamics simulation in soft-matter physics is to sample from models of this form (but composed of $N \gg 2$ dipoles). 

These models do not contain divergences at large $\normbrackets{\rvec_i - \rvec_j}$ because the compactness of $\Omega$ imposes $\normbrackets{\rvec_i - \rvec_j} < \sqrt{3} L / 2$, where $L^3$ is the volume of $\Omega$. We note that we must define $\normbrackets{\rvec_i - \rvec_j}^{-a}$ models on compact subspaces in order to ensure finite total probability mass. However, the intermolecular potentials are composed of functions that diverge as the particle separation tends to zero. The aim of this project is to create an algorithm that is numerically stable as $\normbrackets{\rvec_i - \rvec_j} \to 0$. 

[We should also note that the harmonic-spring potential creates additional stability issues when $k_h \gg k_c, k_{lj}$, which is often the case, e.g., often, $k_h \sim O(100)$. This is because the numerical time-step size used in molecular-dynamics cannot be larger than half the period length of a harmonic-spring oscillation.]

In order to analyse the $\normbrackets{\rvec_i - \rvec_j} \to 0$ instability, we define the two-particle soft-matter potential
\begin{align}
U_{sm}(\rvec_1, \rvec_2) = \pm a^{-1} \normbrackets{\rvec_1 - \rvec_2}^{-a} + U_{\rm{self}} ,
\end{align}
where $a \ge 1$ is an integer. 
For simplicity, we fix the position of particle 1 and assume one-dimensional motion of particle 2 in a straight line towards particle 1. This allows us to rewrite the potential in terms of a single one-dimensional coordinate $r \in (-L / 2, L / 2]$ (where we've discounted $L / 2 < \absbrackets{x} < \sqrt{3}L / 2$, for simplicity):
\begin{align}
U_{sm}(x) = \pm a^{-1} \absbrackets{x}^{-a} + U_{\rm{self}} .
\end{align}


\section{Hamiltonian Monte Carlo dynamics and the composite gradient}

To simulate \HMC , we then define the Hamiltonian:
\begin{align}
H(p, x) = K_b(p) + U(x) ,
\end{align}
where
\begin{align}
K_b(p) = b^{-1} \absbrackets{p}^{b} 
\end{align}
is the generalised-power kinetic energy, $b / 2 \ge 1$ is an integer, and $U$ is some arbitrary potential. The standard choice sets $b = 2$, but we will show below that it can be favourable to choose $b \ne 2$~\cite{Livingstone2019Kinetic}. For the case of the soft-matter potential $U_{sm}$, this generates the continuum dynamics: 
\begin{align} \label{eq:HamiltonianDynamics}
\xdot =& \, \partial_p H = p \absbrackets{p}^{b - 2} ; \\
\pdot =& \, - \partial_x H = \pm x \absbrackets{x}^{- a - 2} .
\end{align}

\HMC\ then numerically solves this set of coupled differential equations in order to generate a new candidate configuration, which is then either accepted or rejected via a Metropolis-Hastings step. For some initial configuration $x_0, p_0$, solving \eq{eq:HamiltonianDynamics} for $T$ units of time gives 
\begin{align}
x^* = x_0 + \int_0^T \partial_p H \bracketsd{p_0 - \int_0^s \partial_x H \bracketsc{x(u)} du} ds.
\end{align}
An explicit numerical method typically applies approximations of the form  
\begin{align}\label{eq:NumericalApprox}
\int_0^{\varepsilon} \partial_x H \bracketsc{x(u)} du \simeq \partial_x H (x_0) \varepsilon
\end{align} 
for some suitably chosen step size $\varepsilon$. For the case of the leapfrog integrator, the approximate solution over a single leapfrog step becomes
\begin{align}\label{eq:NumericalXDynamics}
x_{\varepsilon} = x_0 + \varepsilon \, \partial_p H \bracketsc{p_0 - \frac{\varepsilon}{2} \partial_x H \bracketsb{x_0}} ,
\end{align}
with the corresponding momentum update 
\begin{align}
p_{\varepsilon} = p_0 - \frac{\varepsilon}{2} \bracketsc{\partial_x H \bracketsb{x_0} + \partial_x H \bracketsb{x_{\varepsilon}}} .
\end{align}

Since $\partial_p H$ is an odd function, it follows from \eq{eq:NumericalXDynamics} that the composite gradient
\begin{align}
\partial_p H \circ \partial_x H (x)
\end{align}
will often intuitively governs the \emph{numerical speed} $\absbrackets{\Delta x / \Delta t}$ of the particle dynamics when $\absbrackets{\partial_x H (x)} \gg \absbrackets{p_0}$. It then follows that 
\begin{align}
\absbrackets{\frac{\Delta x}{\Delta t}} \simeq \absbrackets{x}^{-(a + 1)(b - 1)} 
\end{align}
when $\absbrackets{\partial_x H (x)} \gg \absbrackets{p_0}$. 

Similarly, for potentials of the form $ U_{\rm bayes}(x) = a^{-1} \absbrackets{x}^a$ ($x \in \RR$) used in Bayesian computation, we previously showed that the numerical speed of the $x$-coordinate is given by~\cite{Livingstone2019Kinetic}
\begin{align}
\absbrackets{\frac{\Delta x}{\Delta t}} \simeq \absbrackets{x}^{(a - 1)(b -1)} 
\end{align}
when $\absbrackets{\partial_x H (x)} \gg \absbrackets{p_0}$. Potentials of this form contain divergences in the limit $\absbrackets{x} \to \infty$. In order to ensure stability of the numerical approximations used in \eq{eq:NumericalXDynamics}, the numerical speed be at least constant in the diverging coordinate, and must increase at most linearly with the diverging coordinate. In the Bayesian case, the diverging coordinate is $\absbrackets{x}$, from which it follows that we require $(a - 1)(b -1) \ge 0$ and
\begin{align}
\lim_{\absbrackets{x} \to \infty} \bracketsc{\absbrackets{x}^{(a - 1)(b -1) - 1}} = \lim_{\absbrackets{x} \to \infty} \bracketsb{\frac{\absbrackets{\Delta x / \Delta t}}{\absbrackets{x}}} < \infty .
\end{align}
For all $a \ge 2$, stable numerical dynamics therefore follows for momentum exponent $b = b_{\rm bayes}$, where 
\begin{align}
1 \le b_{\rm bayes} \le 1 + \frac{1}{a - 1} ,
\end{align}
where we note that stability of the numerical approximations used in \eq{eq:NumericalXDynamics} is also ensured for large $\absbrackets{p_0}$. 
For example, the momentum exponent $1 \le b_{\rm bayes} \le 4 / 3$ would produce stable numerical dynamics for potentials of the form $\absbrackets{x}^4$. 

Returning to the soft-matter potential $U_{sm}$, the diverging coordinate is now $\absbrackets{x}^{-1}$ (as $\absbrackets{x} \to 0$). The numerical speed must therefore be at least constant in $\absbrackets{x}^{-1}$, and must increase at most linearly with $\absbrackets{x}^{-1}$ in the limit $\absbrackets{x} \to 0$. We therefore require $(a + 1)(b - 1) \ge 0$ and
\begin{align}
\lim_{\absbrackets{x} \to 0} \bracketsd{\absbrackets{x}^{-[(a + 1)(b -1) - 1]}} = \lim_{\absbrackets{x} \to 0} \bracketsb{\frac{\absbrackets{\Delta x / \Delta t}}{\absbrackets{x}^{-1}}} < \infty .
\end{align}
Stable numerical dynamics therefore follows for momentum exponent $b = b_{sm}$, where 
\begin{align}
1 \le b_{sm} \le 1 + \frac{1}{a + 1} ,
\end{align}
where, again, we note that stability of the numerical approximations used in \eq{eq:NumericalXDynamics} is also ensured for large $\absbrackets{p_0}$. 
For example, the momentum exponent $1 \le b_{sm} \le 3 / 2$ would produce stable numerical dynamics for electrostatic potentials of the form $\absbrackets{x}^{-1}$, while the momentum exponent $1 \le b_{sm} \le 14 / 13$ would produce stable numerical dynamics for Lennard-Jones potentials of the form $\absbrackets{x}^{-12}$. Assuming no sub-potential diverges more quickly than the Lennard-Jones potential as $\absbrackets{x} \to 0$, all-atom models in soft matter therefore require momentum exponent 
\begin{align}
1 \le b_{sm} \le 14 / 13
\end{align}
in order to ensure stable numerical dynamics. 

We will therefore test the upper and lower bounds of $b_{sm}$ for each of the electrostatic and Lennard-Jones potentials (on their own) and then the upper and lower bounds of the Lennard-Jones $b_{sm}$ for the model of charge-neutral dipoles. For each case, we will test $N = 2$ and $N \gg 2$ molecules. 

We also note~\cite{Livingstone2019Kinetic} that this reduces the error of the approximative electrostatic force function $\tilde{\nabla} U(\{ \rvec_i \}) = \nabla U(\{ \rvec_i \}) + \eta$ [where $U(\{ \rvec_i \}) = \sum_{i, j} U_c(\rvec_i, \rvec_j)$ and $\meana{\eta} = 0$] used in modern soft-matter software packages. This is because 
\begin{align}
\nabla K \bracketsc{p(t = 0) - \frac{\epsilon}{2} \tilde{\nabla} U(\{ \rvec_i \})} = \nabla K \bracketsc{- \frac{\epsilon}{2} \nabla U(\{ \rvec_i \})} + \nabla^2 K \bracketsc{- \frac{\epsilon}{2} \nabla U(\{ \rvec_i \})} p(t = 0) + \dots ,
\end{align}
where $K$ is the kinetic energy. Here, we have Taylor expanded $\nabla K \bracketsc{p(t = 0) - \epsilon \tilde{\nabla} U(\{ \rvec_i \}) / 2}$ about $- \epsilon \nabla U(\{ \rvec_i \}) / 2$. In the Gaussian case, $\nabla^2 K(p) = 1$, so the refreshed momentum $p_0$ interacts linearly with the composite gradient term regardless of the current position in the state space. If, however, the momentum distribution is chosen to have heavier-than-Gaussian tails, then $\nabla^2 K(p)$ will become negligibly small when $\absbrackets{\nabla U(x_0)}$ is large, reducing the influence of $p_0$ [in particular, the Laplacian kinetic energy ($b = 1$) removes all error because the higher order derivatives of the Laplacian kinetic energy are zero]. A sampler with a flow of this type will move towards a high-density region of the space in an almost deterministic fashion when the diverging coordinate is large~\cite{Livingstone2019Kinetic}. 


\section{Super-relativistic kinetic energy}

However, $b = b_{sm / \text{bayes}}$ may induce slow dynamics in the stable regions. We should therefore also test the super-relativistic kinetic energy~\cite{Livingstone2019Kinetic}:
\begin{align}
K_{\rm sup-rel}(p) = \frac{1}{b_{sm / \text{bayes}}} \bracketsb{1 + \gamma^{-1} p^2}^{b_{sm / \text{bayes}} / 2} .
\end{align}
This generates the dynamics:
\begin{align}
\xdot =& \, \gamma^{-1} p \bracketsb{1 + \gamma^{-1} p^2}^{b_{sm / \text{bayes}} / 2 - 1} \nonumber \\
\sim & \,
\begin{cases} 
\gamma^{-1} \, p &\text{if} \,\, p^2 \ll \gamma , \\
\gamma^{-b_{sm / \text{bayes}} / 2} \, \text{sign}(p) \absbrackets{p}^{b_{sm / \text{bayes}} - 1} &\text{if} \,\, p^2 \gg \gamma ,
\end{cases} 
\end{align}
which stabilises the flow at large $\absbrackets{p}$ while retaining Gaussian-momentum dynamics at small $\absbrackets{p}$. 

We note that the super-relativistic kinetic energy was adapted from the relativistic kinetic energy of Lu et al~\cite{Lu2017Relativistic}:
\begin{align}
K_{\rm rel}(p) = \bracketsb{1 + \gamma^{-1} p^2}^{1 / 2} .
\end{align}
This generates the dynamics:
\begin{align}
\xdot =& \, \frac{p}{\gamma \bracketsb{1 + \gamma^{-1} p^2}^{1/2}} \nonumber \\
\sim & \,
\begin{cases} 
\gamma^{-1} \, p &\text{if} \,\, p^2 \ll \gamma , \\
\gamma^{-1 / 2} \, \text{sign}(p) &\text{if} \,\, p^2 \gg \gamma .
\end{cases} 
\end{align}
We will therefore test the relativistic and super-relativistic kinetic energies.

It is interesting to consider the generalisation of the relativistic energy to 
\begin{align}
K(p) = \bracketsb{1 + \gamma^{-1} p^m}^{1 / m} , \, m / 2 \in \mathbb{N} ,
\end{align}
which generates the dynamics 
\begin{align}
\xdot =& \, \gamma^{-1} \bracketsc{\frac{p}{\bracketsb{1 + \gamma^{-1} p^m}^{1/m}}}^{m - 1} \nonumber \\
\sim & \,
\begin{cases} 
\gamma^{-1} \, p^{m - 1}  &\text{if} \,\, p^m \ll \gamma , \\
\gamma^{-1 / m} \, \text{sign}(p) &\text{if} \,\, p^m \gg \gamma 
\end{cases} \\
\to & \,
\begin{cases} 
\gamma^{-1} \, p^{m - 1}  &\text{if} \,\, p^m \ll \gamma , \\
\text{sign}(p) &\text{if} \,\, p^m \gg \gamma 
\end{cases} 
\end{align}
as $m \to \infty$. This is an interesting result, but shows that $\absbrackets{\xdot} \to 0$ for $\absbrackets{p} < 1$. We therefore won't test this kinetic energy. 

Finally, we extend the super-relativistic kinetic energy to $N$ particles on $\Omega$:
\begin{align} \label{eq:RelKEManyParticles}
K_{\rm sup-rel}(\{ \pvec_i : i = 1, \dots N \}) = \frac{1}{b_{sm / \text{bayes}}} \sum_{i = 1}^N \bracketsb{1 + \gamma^{-1} \normbrackets{\pvec_i}^2}^{b_{sm / \text{bayes}} / 2} ,
\end{align}
which generates
\begin{align}
\dot{\rvec_i} =& \, \gamma^{-1} \pvec_i \bracketsb{1 + \gamma^{-1} \normbrackets{\pvec_i}^2}^{b_{sm / \text{bayes}} / 2 - 1} \nonumber \\
\sim & \,
\begin{cases} 
\gamma^{-1} \, \pvec_i &\text{if} \, \normbrackets{\pvec_i}^2 \ll \gamma , \\
\gamma^{-1 / 2} \, \pvec_i \normbrackets{\pvec_i}^{b_{sm / \text{bayes}} - 2} &\text{if} \, \normbrackets{\pvec_i}^2 \gg \gamma .
\end{cases} 
\end{align}
We note that it may be sensible to decouple the Cartesian components ($p_{i, x}, p_{i, y}, p_{i, z}$) of the momentum of each particle in \eq{eq:RelKEManyParticles}. An analogous kinetic energy can be defined for the relativistic case. 

We will therefore test the relativistic and super-relativistic kinetic energies for the models outlined above, both with and without the Cartesian decoupling. 



\section{Total flow time}

At some fixed level set $E$ of $H(x, p) - U_{\rm{self}}$, the total flow time $T(E)$ satisfies $U(t = 0) = \minb{U}$ and $p[t = T(E)] = 0$. We express the total flow time in terms of an integral of a function of the momentum $p$:
\begin{align}
T(E) = \int_{x(0)}^{x(T)} \frac{dt}{dx} dx = \int_{x(0)}^{x(T)} \frac{\absbrackets{p}^{2 - b}}{p} dx .
\end{align}
This quantity is a measure of the stability of the dynamics because the average speed of the particle 
\begin{align}
S(E) = \frac{d(T)}{T(E)} ,
\end{align}
where $d(T)$ is the total distance covered (in $x$ space) between times $t = 0$ and $t = T(E)$. Average speeds between linear in and independent of $d(T)$ are stable, from which it follows that flow times $T(E)$ between independent of and linear in $d(T)$ are stable. This is useful for proving the above derivations of the exponents $b_{sm / \text{bayes}}$. 

For some arbitrary potential $U$, the dynamics generated by a Laplacian kinetic energy ($b = 1$) are stable:
\begin{align}
T(E) = \int_{x(0)}^{x(T)} \text{sign}(p) dx = \pm \bracketsc{x(T) - x(0)} = d(T) .
\end{align}
This implies a stable flow whose period length increases linearly with the distance travelled, which implies constant average speed $S(E)$ for all levels sets $E$. 

For the generalised-power kinetic energy $K_b$ and Bayesian potential $U_{\rm bayes}$, we previously showed that $T(E) = f(E^{\bracketsc{1 - (a - 1)(b - 1)} / a b})$~\cite{Livingstone2019Kinetic}. Assuming $x(t=0) = 0$ and $p(t = 0) > 0$, which implies that $x(t = T) = (aE)^{1 / a}$ (where $E > 0$), and using $p(t) = \bracketsd{b\bracketsc{E - \absbrackets{x(t)}^a / a}}^{1 / b}$ and setting $c = (1 - b) / b$, the total flow time is then given by 
\begin{align}
T(E) =& \, \int_0^{(aE)^{1 / a}} p^{1 - b} dx \nonumber\\
=& \, \int_0^{(aE)^{1 / a}} \bracketsd{b\bracketsc{E - \frac{1}{a} \absbrackets{x(t)}^a}}^c dx \nonumber\\
=& \, b^{c} E^{c} \int_0^{(aE)^{1 / a}} \bracketsb{1 - \frac{1}{Ea} \absbrackets{x(t)}^a}^c dx \nonumber\\
=& \, b^{c} E^{c + 1 / a} \int_0^1 \bracketsb{1 - \absbrackets{y(t)}^a}^c dy .
\end{align}
This result implies stable dynamics for $b = 1 + 1 / (a - 1)$ because the flow time $T$ is then independent of $E$. Given that Laplacian dynamics are stable for any potential, it then follows that dynamics are stable for all $1 \le b_{\rm bayes} \le 1 + 1 / (a - 1)$ (for $a \ge 1$), and that the $b = 1$ limit is the most stable, as above. 

However, this method cannot be so easily applied to soft-matter potentials. For example, for the like-charge electrostatic potential, and assuming $x(t=0) = -L / 2$ and $p(t = 0) > 0$, which implies that $x(t = T) = - 1 / E$ (where $E > 0$), and using $p(t) = \bracketsd{b\bracketsc{E - 1 / \absbrackets{x(t)}}}^{1 / b}$, the total flow time is then given by 
\begin{align}
T(E) =& \, \int_{- L / 2}^{- 1 / E} p^{1 - b} dx \nonumber\\
=& \, \int_{- L / 2}^{- 1 / E} \bracketsc{b\bracketsb{E - \frac{1}{\absbrackets{x}}}}^{c} dx \nonumber\\
=& \, b^{c} E^{c} \int_{- L / 2}^{- 1 / E} \bracketsb{1 + \frac{1}{E x}}^{c} dx \nonumber\\
=& \, b^{c} E^{c - 1} \int_{- E L / 2}^{-1} \bracketsb{1 - \frac{1}{\absbrackets{y}}}^{c} dy \label{eq:PeriodLengthLikeCharges} .
\end{align}
Similarly, for opposite charges [assuming $x(t=0) = x_0 > a$, $p(t = 0) > 0$, $x(t = T) = - 1 / E \le L / 2$ (where $E < 0$)]: 
\begin{align}
T(E) = b^{c} \absbrackets{E}^c \int_{x_0}^{-1 / E} \bracketsb{1 + \frac{1}{E x}}^{c} dx = b^{c} \absbrackets{E}^{c - 1} \int_{E x_0}^{-1} \bracketsb{1 - \frac{1}{\absbrackets{y}}}^{c} dy \label{eq:PeriodLengthOppositeCharges} .
\end{align}
Factoring $E$ out of the integral is therefore not as straightforward as in the Bayesian case. This is because the divergence at $\absbrackets{x} \to 0$ requires either some function of $E$ in the limits of the flow-time integral or a divergent flow time (i.e., $L \to \infty$). 


\section{Temperature-generalised kinetic energy}

We now outline a relatively straightforward idea that should allow for sampling from the canonical ensemble at different (inverse) temperatures $\beta$ from a single set of tuning parameters. The following doesn't seem to appear in the literature. 

We define the temperature-generalised Hamiltonian $\tilde{H}(p, x; \beta) := \beta H(p, x)$ and kinetic energy $\tilde{K}(p; \beta) := \beta K(p)$. The temperature-generalised Hamiltonian dynamics, 
\begin{align} \label{eq:TempGenHamiltonianDynamics}
\xdot =& \, \partial_p \tilde{H}  ; \\
\pdot =& \, - \partial_x \tilde{H}  ,
\end{align}
then allow the user to sample from the canonical ensemble, i.e., potentials of the form $\beta U_{sm}$, using a single set of tuning parameters. Effectively, the time-step size at $\beta$ is then just given by $\beta \epsilon (\beta = 1)$. This temperature generalisation can be applied to any kinetic energy, and therefore to super-relativistic Monte Carlo.


\section{Nonequilibrium sampling}

An additional relatively simple idea could also be very powerful for nonequilibrium sampling. Again, this doesn't seem to appear in the literature. 

\begin{enumerate}
\item Fix the target sampling (inverse) temperature $\beta$.
\item Set a random configuration.
\item Run super-relativistic Monte Carlo with $\tilde{K}_{\rm sup-rel}$ until equilibrium is reached. 
\item Run standard \HMC\ with $\tilde{K}_{b = 2}$ until a new configuration is accepted.
\item The trajectory that led to this accepted configuration is defined as an observation of the \emph{nonequilibrium sample}.
\item Go to 4 $l$ times.
\item Go to 2 $m$ times.
\item Analyse the nonequilbrium sample.
\end{enumerate}

Finally, we could integrate all resultant code into Stan --  called `soft-Stan'??


\section{Plan d'action}

\begin{enumerate}
\item Gaussian, Laplacian, rel and super-rel kinetic energies for two Lennard-Jones particles. 
\item Gaussian, Laplacian, rel and super-rel kinetic energies for two like charges (with and without the $O\bracketsc{N \logb{N}}$ electrostatic-force approximation). 
\item Compare instabilities, step size, etc. for the electrostatic and Lennard-Jones cases (with and without the $O\bracketsc{N \logb{N}}$ electrostatic-force approximation) -- create a prescription for $\gamma$. 
\item Gaussian, Laplacian, rel and super-rel kinetic energies for $N \gg 2$ Lennard-Jones particles. 
\item Gaussian, Laplacian, rel and super-rel kinetic energies for $N \gg 2$ like charges (with the $O\bracketsc{N \logb{N}}$ approximation). 
\item For $10$ to $50$ like point charges, compare electrostatic instabilities with and without the $O\bracketsc{N \logb{N}}$ approximation. 
\item Gaussian, Laplacian, rel and super-rel kinetic energies for two dipoles (composed of Lennard-Jones, electrostatic and quadratic potentials). 
\item Gaussian, Laplacian, rel and super-rel kinetic energies for $N \gg 2$ dipoles (with the $O\bracketsc{N \logb{N}}$ approximation). 
\end{enumerate}

\bibliographystyle{IEEEtran}
\bibliography{Faulkner,ThisProject}
\end{document}
