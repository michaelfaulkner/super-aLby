"""Module for the MarkovChain class."""
import numpy as np


class MarkovChain:
    """
    MarkovChain class.

    The class provides the Markov-chain function (as run()).
    """

    def __init__(self, integrator_instance, potential_instance, kinetic_energy_instance, initial_step_size=1,
                 max_number_of_integration_steps=10, number_of_equilibration_iterations=100,
                 number_of_observations=1100, use_metropolis_accept_reject=True,
                 randomise_number_of_integration_steps=False):
        """
        The constructor of the MarkovChain class.

        Parameters
        ----------
        integrator_instance : Python class instance

        potential_instance : Python class instance

        kinetic_energy_instance : Python class instance

        initial_step_size : int, optional

        max_number_of_integration_steps : int, optional

        number_of_equilibration_iterations : int, optional

        number_of_observations : int, optional

        use_metropolis_accept_reject : Boolean, optional

        randomise_number_of_integration_steps : Boolean, optional

        Raises
        ------
        base.exceptions.ValueError
            If the prefactor equals 0.
        """
        if initial_step_size == 0:
            raise ValueError(
                "Give a value not equal to 0 as the initial step size of the numerical integrator {0}.".format(
                    self.__class__.__name__))
        if max_number_of_integration_steps == 0:
            raise ValueError(
                "Give a value not equal to 0 as the maximum number of numerical integration steps {0}.".format(
                    self.__class__.__name__))
        if number_of_equilibration_iterations >= number_of_observations:
            raise ValueError("Set equilibration iterations to less than the number of observations {0}.".format(
                self.__class__.__name__))
        if number_of_observations == 0:
            raise ValueError(
                "Give a value not equal to 0 as the number of observations of target distribution {0}.".format(
                    self.__class__.__name__))
        self._integrator_instance = integrator_instance
        self._potential_instance = potential_instance
        self._kinetic_energy_instance = kinetic_energy_instance
        self._step_size = initial_step_size
        self._max_number_of_integration_steps = max_number_of_integration_steps
        self._number_of_equilibration_iterations = number_of_equilibration_iterations
        self._number_of_observations = number_of_observations
        self._use_metropolis_accept_reject = use_metropolis_accept_reject
        self._randomise_number_of_integration_steps = randomise_number_of_integration_steps

    def run(self, support_variable, charges=None):
        """
        Runs the Markov chain and returns the generated observations of the target and momentum distributions.

        Parameters
        ----------
        support_variable : numpy_array
            For soft-matter models, one or many particle-particle separation vectors {r_ij}; for Bayesian models, the
            parameter value; for the Ginzburg-Landau potential on a lattice, the entire array of superconducting phase.
        charges : optional
            All the charges needed to run the Markov chain.

        Returns
        -------
        float
            The observations (of the target and momentum distributions) generated by the Markov chain.
     """
        number_of_accepted_trajectories = 0
        number_of_numerical_divergences = 0
        number_of_integration_steps = self._max_number_of_integration_steps
        support_variable_dimension = len(np.atleast_1d(support_variable))
        support_variable_sample = np.empty((support_variable_dimension, self._number_of_observations + 1))
        support_variable_sample[:, 0] = support_variable
        momentum_sample = np.empty((support_variable_dimension, self._number_of_observations + 1))
        momentum_sample[:, 0] = np.zeros(support_variable_dimension)

        for i in range(self._number_of_observations):
            momentum = self._kinetic_energy_instance.momentum_observation(len(support_variable))
            if self._randomise_number_of_integration_steps:
                number_of_integration_steps = 1 + np.random.randint(self._max_number_of_integration_steps)
            momentum_candidate, support_variable_candidate = self._integrator_instance.get_flow(
                momentum, support_variable, number_of_integration_steps, self._step_size, charges=None)

            if self._use_metropolis_accept_reject:
                delta_hamiltonian = (self._kinetic_energy_instance.kinetic_energy(momentum_candidate) -
                                     self._kinetic_energy_instance.kinetic_energy(momentum) +
                                     self._potential_instance.potential(support_variable_candidate, charges=charges) -
                                     self._potential_instance.potential(support_variable, charges=charges))
                if abs(delta_hamiltonian) > 1000.0:
                    number_of_numerical_divergences += 1
                if np.random.uniform(0, 1) < np.exp(- delta_hamiltonian):
                    support_variable = support_variable_candidate
                    momentum = momentum_candidate
                    number_of_accepted_trajectories += 1
            else:
                support_variable = support_variable_candidate
                momentum = momentum_candidate
            support_variable_sample[:, i] = support_variable
            momentum_sample[:, i] = momentum

            if i < self._number_of_equilibration_iterations:  # adapt step-size if in equilibration phase
                acceptance_rate = number_of_accepted_trajectories / float(i + 1)
                if acceptance_rate > 0.8:
                    self._step_size *= 1.1
                elif acceptance_rate < 0.6:
                    self._step_size *= 0.9
                number_of_accepted_trajectories = 0
        acceptance_rate = number_of_accepted_trajectories / float(
            self._number_of_observations - self._number_of_equilibration_iterations)
        print("Maximum number of integration steps = %d; numerical step size = %.3f" % (
            self._max_number_of_integration_steps, self._step_size))
        print("Metropolis-Hastings acceptance rate = %f" % acceptance_rate)
        print("Number of numerical divergences = %d" % number_of_numerical_divergences)
        return (
            momentum_sample, support_variable_sample, self._step_size, acceptance_rate, number_of_numerical_divergences)
